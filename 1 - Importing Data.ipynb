{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import SeqFeature\n",
    "from Bio.Alphabet import IUPAC\n",
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "import numpy as np\n",
    "import csv\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import product, combinations\n",
    "from os import listdir, mkdir\n",
    "import pickle\n",
    "#ocf cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "genomes = [f.split(\".\")[0] for f in listdir(\"data\") if \".fasta\" in f]\n",
    "genomes.remove(\"Humans\")\n",
    "alu = [\"AluJb\", \"AluJo\", \"AluJr\", \"AluJr4\", \"AluSc\", \"AluSc5\", \"AluSc8\", \"AluSg\", \"AluSg4\", \"AluSg7\", \"AluSp\", \"AluSq\", \"AluSq10\", \"AluSq2\", \"AluSq4\", \"AluSx\", \"AluSx1\", \"AluSx3\", \"AluSx4\", \"AluSz\", \"AluSz6\", \"AluY\"]\n",
    "# pairings = list(combinations(genomes, 2))\n",
    "# print(len(pairings))\n",
    "print(len(alu))\n",
    "tasks = list(product([\"Humans\"], genomes, alu))\n",
    "create_tasks(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pickles([\"Humans\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Task(tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(obj=t, file=open(t.filename(), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = pickle.load(file=open(t.filename(), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the frequencies for each subfamily in a genome\n",
    "#ex: get_frequencies(\"humans\")\n",
    "class Task():\n",
    "    def __init__(self,task):\n",
    "        self.species1 = task[0]\n",
    "        self.species2 = task[1]\n",
    "        self.subfamily = task[2]\n",
    "        self.total = len(pickle.load(file=open(\"data/\"+self.species1 + \"/\" + self.species1+\"_\"+self.subfamily + \".p\", \"rb\")))\n",
    "        self.completed = 0\n",
    "    def filename(self):\n",
    "        return self.species1 + \"_\" + self.species2 + \"_\" + self.subfamily + \".p\"\n",
    "    def update(self,amount):\n",
    "        self.completed += amount\n",
    "def create_tasks(tasks):\n",
    "#warning: only run once, will reset progress for tasks\n",
    "    task_list = [Task(task) for task in tasks]\n",
    "    pickle.dump(obj=task_list, file=open(\"progress.p\", \"wb\"))\n",
    "def create_pickles(genomes):\n",
    "    d = {}\n",
    "    for g in genomes:\n",
    "        records = SeqIO.parse(\"data/\" + g + \".fasta\", \"fasta\")\n",
    "        for a in alu:\n",
    "            d[a]=[]\n",
    "        for r in records:\n",
    "            subfamily = r.id.split(\"_\")[2]\n",
    "            if subfamily in d.keys():\n",
    "                d[subfamily].append(r)\n",
    "        os.mkdir(\"data/\" + g)\n",
    "        for sub, seqs in d.items():\n",
    "            path = \"data/\" + g + \"/\" + g + \"_\" + sub + \".p\"\n",
    "            pickle.dump(seqs, open(path, \"wb\"))\n",
    "        \n",
    "        \n",
    "def get_frequencies(species):\n",
    "    records = SeqIO.parse(\"data/\" + species + \".fasta\", \"fasta\")\n",
    "    freq = {}\n",
    "    for r in records:\n",
    "        subfamily = r.id.split(\"_\")[2]\n",
    "        freq[subfamily] = freq.get(subfamily, 0) + 1\n",
    "    #uncomment these next three lines out if you want the relative frequencies\n",
    "#     factor=1.0/sum(freq.values())\n",
    "#     for sub in freq:\n",
    "#         freq[sub] = freq[sub]*factor\n",
    "    return freq\n",
    "\n",
    "#return a list of sequences for a given species and subfamily\n",
    "#ex: get_subfamily(\"humans\", \"AluJo\")\n",
    "def get_subfamily(species, subfamily):\n",
    "    records = SeqIO.parse(\"data/\" + species + \".fasta\", \"fasta\")\n",
    "    return [record for record in records if subfamily in record.id]\n",
    "\n",
    "##return a list of sequences for a given species and subfamily on a chromosome\n",
    "#ex: get_subfamily_chr(\"humans\", \"AluJo\", 1)\n",
    "def get_subfamily_chr(species, subfamily, chromosome):\n",
    "    records = get_subfamily(species, subfamily)\n",
    "    return [record for record in records if \"chr\"+str(chromosome) in record.description]\n",
    "\n",
    "#retrieve a sequence for a given speicies based on its description\n",
    "def get_sequence(species, description):\n",
    "    records = SeqIO.parse(\"data/\" + species + \".fasta\", \"fasta\")\n",
    "    return [record for record in records if description == record.description]\n",
    "\n",
    "#parses location information from description string\n",
    "def get_location(description):\n",
    "    location = description.split(' ')[1].split(':')\n",
    "    start, end = location[1].split('-')\n",
    "    return [location[0].split(\"=\")[1], int(start), int(end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alu': 4658,\n",
       " 'AluJb': 131759,\n",
       " 'AluJo': 81375,\n",
       " 'AluJr': 88503,\n",
       " 'AluJr4': 20966,\n",
       " 'AluSc': 36338,\n",
       " 'AluSc5': 7018,\n",
       " 'AluSc8': 23028,\n",
       " 'AluSg': 38681,\n",
       " 'AluSg4': 7603,\n",
       " 'AluSg7': 9159,\n",
       " 'AluSp': 53809,\n",
       " 'AluSq': 19866,\n",
       " 'AluSq10': 2165,\n",
       " 'AluSq2': 63875,\n",
       " 'AluSq4': 1906,\n",
       " 'AluSx': 123022,\n",
       " 'AluSx1': 123492,\n",
       " 'AluSx3': 34198,\n",
       " 'AluSx4': 11540,\n",
       " 'AluSz': 107707,\n",
       " 'AluSz6': 49944,\n",
       " 'AluY': 110881,\n",
       " 'AluYa8': 368,\n",
       " 'AluYd8': 241,\n",
       " 'AluYe5': 1378,\n",
       " 'AluYf1': 2025,\n",
       " 'AluYg6': 899,\n",
       " 'AluYh9': 165,\n",
       " 'AluYi6': 470,\n",
       " 'AluYk11': 1341,\n",
       " 'AluYk12': 219}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequencies(\"humans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Threaded Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pairings(species1, species2, subfamily):\n",
    "    species1_records = get_subfamily(species1, subfamily)\n",
    "    species2_records = get_subfamily(species2, subfamily)\n",
    "    filename = species1 + \"_\" + species1 + \"_\" + subfamily + \".csv\"\n",
    "    file=open(filename,\"w+\")\n",
    "    wr = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "    f = IntProgress(min=0, max=len(species1_records))\n",
    "    display(f)\n",
    "    for sequence1 in species1_records:\n",
    "        matches = [distance(str(sequence1.seq), str(sequence2.seq)) for sequence2 in species2_records]\n",
    "        match = species2_records[np.argmin(matches)]\n",
    "        location1 = get_location(sequence1.description)\n",
    "        location2 = get_location(match.description)\n",
    "        data = np.concatenate([location1, location2, [abs(location1[1] - location2[1])], [str(sequence1.seq)], [str(match.seq)]]) \n",
    "        wr.writerow(data)\n",
    "        f.value += 1\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_pairings(\"humans\", \"chimps\", \"AluJo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreaded Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters here\n",
    "species1 = \"humans\"\n",
    "species2 = \"chimps\"\n",
    "subfamily = \"AluJo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then run this cell\n",
    "print(\"loading \" + species1 + \" data...\")\n",
    "species1_records = get_subfamily(species1, subfamily)\n",
    "print(\"loading \" + species2 + \" data...\")\n",
    "species2_records = get_subfamily(species2, subfamily)\n",
    "generate_pairings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_match(sequence):\n",
    "    matches = [distance(str(sequence.seq), str(sequence2.seq)) for sequence2 in species2_records]\n",
    "    match = species2_records[np.argmin(matches)]\n",
    "    location1 = get_location(sequence.description)\n",
    "    location2 = get_location(match.description)\n",
    "    data = np.concatenate([location1, location2, [abs(location1[1] - location2[1])], [str(sequence.seq)], [str(match.seq)]]) \n",
    "    return data\n",
    "    \n",
    "def generate_pairings():\n",
    "    filename = species1 + \"_\" + species2 + \"_\" + subfamily + \".csv\"\n",
    "    print(\"starting matching\")\n",
    "    p = mp.Pool(mp.cpu_count() + 2)\n",
    "    with open(filename, 'w+') as f:\n",
    "        wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "        with tqdm(total=len(species1_records), unit=\"match\") as pbar:\n",
    "            for i, result in tqdm(enumerate(p.imap(func=find_match, iterable=species1_records))):\n",
    "                # (filename, count) tuples from worker\n",
    "                pbar.update()\n",
    "                wr.writerow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = SeqIO.parse(\"data/\" + \"humans\" + \".fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = SeqIO.parse(\"data/\" + \"chimps\" + \".fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(str(next(h).seq),str(next(c).seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = iter([1, 2, 3, 4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
