{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Levenshtein'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0c97c54944f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlphabet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIUPAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLevenshtein\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Levenshtein'"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import SeqFeature\n",
    "from Bio.Alphabet import IUPAC\n",
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "import numpy as np\n",
    "import csv\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import product, combinations, permutations\n",
    "from os import listdir, mkdir\n",
    "import pickle\n",
    "import timeit\n",
    "from iterated_tasks import Task\n",
    "import edlib\n",
    "import array\n",
    "from collections import Counter\n",
    "from pickle import UnpicklingError\n",
    "#ocf cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3432"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genomes = [f for f in listdir(\"data\") if \"_\" not in f]\n",
    "# genomes.remove(\"Humans\")\n",
    "alu = [\"AluJb\", \"AluJo\", \"AluJr\", \"AluJr4\", \"AluSc\", \"AluSc5\", \"AluSc8\", \"AluSg\", \"AluSg4\", \"AluSg7\", \"AluSp\", \"AluSq\", \"AluSq10\", \"AluSq2\", \"AluSq4\", \"AluSx\", \"AluSx1\", \"AluSx3\", \"AluSx4\", \"AluSz\", \"AluSz6\", \"AluY\"]\n",
    "len(list(product(permutations(genomes, 2), alu)))\n",
    "\n",
    "tasks = list(product(product([\"Humans\"], genomes[:7][::-1]), alu))\n",
    "create_tasks(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for f in listdir(\"tasks\"):\n",
    "    try:\n",
    "        task = pickle.load(file=open(\"tasks/\" + f, \"rb\"))\n",
    "    except UnpicklingError:\n",
    "        errors.append(f)\n",
    "#     task.subsection = None\n",
    "#     pickle.dump(task, open(\"tasks/\"+task.filename(), \"wb\"))\n",
    "# pickle.dump(t, open(\"tasks/\"+t.filename(), \"wb\"))\n",
    "\n",
    "file = errors[0]\n",
    "names = file.split(\"_\")\n",
    "task = Task(((names[0], names[1]), names[2].split(\".\")[0]))\n",
    "with open(\"results/\"+file+\".csv\") as f:\n",
    "    task.completed = sum(1 for line in f) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter([1, 1, 1, 1, 1, 2, 3, 4, 3, 4, 3, 4, 4, 4, 4, 1, 1])\n",
    "def get_order(c):\n",
    "    ordering = {}\n",
    "    for key, value in c.most_common():\n",
    "        ordering[key] = len(ordering)\n",
    "    def order(chromosome):\n",
    "        if chromosome in ordering.keys():\n",
    "            return ordering[chromosome]\n",
    "        else:\n",
    "            return len(ordering)\n",
    "    return order\n",
    "get_order(c)(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in errors:\n",
    "    names = file.split(\"_\")\n",
    "    task = Task(((names[0], names[1]), names[2].split(\".\")[0]))\n",
    "    with open(\"results/\"+file+\".csv\") as f:\n",
    "        task.completed = sum(1 for line in f) - 1\n",
    "    pickle.dump(task, open(\"tasks/\"+file, \"wb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(((\"Humans\", \"Chimps\"), \"AluY\"))\n",
    "task.completed = 100000\n",
    "batch_size = 100\n",
    "species1_records = pickle.load(open(\"data/\" + task.species1 + \"/\" + task.species1 + \"_\" + task.subfamily + \".p\", \"rb\"))[task.completed:task.completed+batch_size]\n",
    "species2_records = pickle.load(open(\"data/\" + task.species2 + \"/\" + task.species2 + \"_\" + task.subfamily + \".p\", \"rb\"))\n",
    "species2_chr = [get_location(sequence2.description)[0] for sequence2 in species2_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6553196334838867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.04370713233948"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "times = []\n",
    "datas = []\n",
    "c = Counter()\n",
    "for sequence1 in species1_records:\n",
    "    order = get_order(c)\n",
    "#     [sequence2 for _, x in sorted(zip(species2_chr,species2_records), key=lambda pair: order(pair[0]))]\n",
    "    # matches = [editdistance.eval(str(sequence1.seq), str(sequence2.seq)) for sequence2 in species2_records]\n",
    "    k = 300\n",
    "    match = \"\"\n",
    "    new_order = sorted(zip(species2_chr,species2_records), key=lambda pair: order(pair[0]))\n",
    "    t1 = time.time()\n",
    "    for _, sequence2 in new_order:\n",
    "#     for sequence2 in species2_records:\n",
    "        k_new = edlib.align(str(sequence1.seq), str(sequence2.seq), task = \"editDistance\", k = k)[\"editDistance\"]\n",
    "        if k_new != -1 and k_new < k:\n",
    "            match = sequence2\n",
    "            k = k_new\n",
    "    times.append(time.time()-t1)\n",
    "    # min_index = np.argmin(matches)\n",
    "    # match = species2_records[min_index]\n",
    "    location1 = get_location(sequence1.description)\n",
    "    location2 = get_location(match.description)\n",
    "    c[location2[0]] += 1\n",
    "    data = np.concatenate([location1, location2, [k], [abs(location1[1] - location2[1])]])\n",
    "    datas.append(data)\n",
    "# print(datas[0])\n",
    "# print(datas[-1])\n",
    "print(np.average(times))\n",
    "time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052996158599853516"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "# sorted(species2_chr)\n",
    "[x for _, x in sorted(zip(species2_chr,species2_records), key=lambda pair: order(pair[0]))][0]\n",
    "time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'Task' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ea4547000896>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tasks/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tasks\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# started = [task for task in tasks if task.species1 == \"Humans\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfinished\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtask\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtasks\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinished\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinished\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# df = pd.read_csv(\"results/\"+started[0].filename()+\".csv\", header=None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ea4547000896>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tasks/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tasks\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# started = [task for task in tasks if task.species1 == \"Humans\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfinished\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtask\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtasks\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinished\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinished\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# df = pd.read_csv(\"results/\"+started[0].filename()+\".csv\", header=None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'Task' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "tasks = [pickle.load(file=open(\"tasks/\" + f, \"rb\")) for f in listdir(\"tasks\")]\n",
    "# started = [task for task in tasks if task.species1 == \"Humans\"]\n",
    "finished = [task for task in tasks if task.finished()]\n",
    "print(len(finished))\n",
    "# df = pd.read_csv(\"results/\"+started[0].filename()+\".csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = [f for f in listdir(\"data\") if \"_\" not in f]\n",
    "genomes.remove(\"Humans\")\n",
    "for a in alu[:1]:\n",
    "    for genome in genomes[:1]:\n",
    "        string = []\n",
    "        for task in started:\n",
    "            if task.species2 == genome and task.subfamily == alu:\n",
    "                df = pd.read_csv(\"results/\"+task.filename()+\".csv\", header=None)\n",
    "                print(df['8'].str.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>192937858</td>\n",
       "      <td>192938175</td>\n",
       "      <td>chr1</td>\n",
       "      <td>171366085</td>\n",
       "      <td>171366402</td>\n",
       "      <td>24</td>\n",
       "      <td>21571773</td>\n",
       "      <td>GCCGGGCATGGTGGCTCACTCTTGTTAATCCCAGCACTTTGGGAAG...</td>\n",
       "      <td>GCCGGGCATGGTGGCTCATTCTTGTTAATCCCAGCACTTTGGGAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>24117116</td>\n",
       "      <td>24117383</td>\n",
       "      <td>chr1</td>\n",
       "      <td>26355737</td>\n",
       "      <td>26356001</td>\n",
       "      <td>25</td>\n",
       "      <td>2238621</td>\n",
       "      <td>CCCAGCACTTTGGGAGGCCAAGGTGGAGGATCACTTGGGTCCAGGA...</td>\n",
       "      <td>CCCAGCACTTTGGGAGGCCAAGGCGGAGGATCACTTGAGCCCAGGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>32505606</td>\n",
       "      <td>32505884</td>\n",
       "      <td>chr1</td>\n",
       "      <td>34701911</td>\n",
       "      <td>34702187</td>\n",
       "      <td>25</td>\n",
       "      <td>2196305</td>\n",
       "      <td>GGCCAGGTGGTGGCTTATATCTGTAATCCCACCACTTTGGGAGGCT...</td>\n",
       "      <td>GGCCAGGTGGTGGCTTATATCTATAATCCCATCACTTTGGGAGGCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>54525648</td>\n",
       "      <td>54525956</td>\n",
       "      <td>chr9</td>\n",
       "      <td>95122753</td>\n",
       "      <td>95123061</td>\n",
       "      <td>48</td>\n",
       "      <td>40597105</td>\n",
       "      <td>GGCCAGGCACAGCGGCTCACACCTGTAATCCCAGCACTTTGGGAGG...</td>\n",
       "      <td>GGCCAGGTGCAGGGGCTCACGCCTATAATCCTAGTACTTTGGGAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>236977955</td>\n",
       "      <td>236978230</td>\n",
       "      <td>chr1</td>\n",
       "      <td>212128917</td>\n",
       "      <td>212129192</td>\n",
       "      <td>26</td>\n",
       "      <td>24849038</td>\n",
       "      <td>GGCTGGGCGTGGTGGCTCATGCCTATAATCCCAGCACTTTGGGAAG...</td>\n",
       "      <td>GGCTGGGTGTGGTGGCTCATGCCTATAATCCCAGCACTTTGGGAAG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0          1          2     3          4          5   6         7  \\\n",
       "0  chr1  192937858  192938175  chr1  171366085  171366402  24  21571773   \n",
       "1  chr1   24117116   24117383  chr1   26355737   26356001  25   2238621   \n",
       "2  chr1   32505606   32505884  chr1   34701911   34702187  25   2196305   \n",
       "3  chr1   54525648   54525956  chr9   95122753   95123061  48  40597105   \n",
       "4  chr1  236977955  236978230  chr1  212128917  212129192  26  24849038   \n",
       "\n",
       "                                                   8  \\\n",
       "0  GCCGGGCATGGTGGCTCACTCTTGTTAATCCCAGCACTTTGGGAAG...   \n",
       "1  CCCAGCACTTTGGGAGGCCAAGGTGGAGGATCACTTGGGTCCAGGA...   \n",
       "2  GGCCAGGTGGTGGCTTATATCTGTAATCCCACCACTTTGGGAGGCT...   \n",
       "3  GGCCAGGCACAGCGGCTCACACCTGTAATCCCAGCACTTTGGGAGG...   \n",
       "4  GGCTGGGCGTGGTGGCTCATGCCTATAATCCCAGCACTTTGGGAAG...   \n",
       "\n",
       "                                                   9  \n",
       "0  GCCGGGCATGGTGGCTCATTCTTGTTAATCCCAGCACTTTGGGAAG...  \n",
       "1  CCCAGCACTTTGGGAGGCCAAGGCGGAGGATCACTTGAGCCCAGGA...  \n",
       "2  GGCCAGGTGGTGGCTTATATCTATAATCCCATCACTTTGGGAGGCT...  \n",
       "3  GGCCAGGTGCAGGGGCTCACGCCTATAATCCTAGTACTTTGGGAGG...  \n",
       "4  GGCTGGGTGTGGTGGCTCATGCCTATAATCCCAGCACTTTGGGAAG...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = [f.split(\".\")[0] for f in listdir(\"data\") if \".fasta\" in f]\n",
    "alu = [\"AluJb\", \"AluJo\", \"AluJr\", \"AluJr4\", \"AluSc\", \"AluSc5\", \"AluSc8\", \"AluSg\", \"AluSg4\", \"AluSg7\", \"AluSp\", \"AluSq\", \"AluSq10\", \"AluSq2\", \"AluSq4\", \"AluSx\", \"AluSx1\", \"AluSx3\", \"AluSx4\", \"AluSz\", \"AluSz6\", \"AluY\"]\n",
    "create_pickles(genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Task(tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(obj=t, file=open(t.filename(), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = pickle.load(file=open(t.filename(), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the frequencies for each subfamily in a genome\n",
    "#ex: get_frequencies(\"humans\")\n",
    "class Task():\n",
    "    def __init__(self,task):\n",
    "        self.species1 = task[0][0]\n",
    "        self.species2 = task[0][1]\n",
    "        self.subfamily = task[1]\n",
    "        self.total = len(pickle.load(file=open(\"data/\"+self.species1 + \"/\" + self.species1+\"_\"+self.subfamily + \".p\", \"rb\")))\n",
    "        self.completed = 0\n",
    "    def filename(self):\n",
    "        return self.species1 + \"_\" + self.species2 + \"_\" + self.subfamily + \".p\"\n",
    "    def update(self,amount):\n",
    "        self.completed += amount\n",
    "    def finished(self):\n",
    "        return self.completed == self.total\n",
    "    def remaining(self):\n",
    "        return self.total - self.completed\n",
    "    def __eq__(self, obj):\n",
    "        return (self.species1 == obj.species1) & (self.species2 == obj.species2) & (self.subfamily == obj.subfamily)\n",
    "def create_tasks(tasks):\n",
    "#warning: only run once, will reset progress for tasks\n",
    "    for task in tasks:\n",
    "        t = Task(task)\n",
    "        pickle.dump(t, open(\"tasks/\"+t.filename(), \"wb\"))\n",
    "#     task_list = [Task(task) for task in tasks]\n",
    "#     pickle.dump(obj=task_list, file=open(\"progress.p\", \"wb\"))\n",
    "def create_pickles(genomes):\n",
    "    d = {}\n",
    "    for g in genomes:\n",
    "        records = SeqIO.parse(\"data/\" + g + \".fasta\", \"fasta\")\n",
    "        for a in alu:\n",
    "            d[a]=[]\n",
    "        for r in records:\n",
    "            subfamily = r.id.split(\"_\")[2]\n",
    "            if subfamily in d.keys():\n",
    "                d[subfamily].append(r)\n",
    "        mkdir(\"data/\" + g)\n",
    "        for sub, seqs in d.items():\n",
    "            path = \"data/\" + g + \"/\" + g + \"_\" + sub + \".p\"\n",
    "            pickle.dump(seqs, open(path, \"wb\"))\n",
    "        \n",
    "        \n",
    "def get_frequencies(species):\n",
    "    records = SeqIO.parse(\"data/\" + species + \".fasta\", \"fasta\")\n",
    "    freq = {}\n",
    "    for r in records:\n",
    "        subfamily = r.id.split(\"_\")[2]\n",
    "        freq[subfamily] = freq.get(subfamily, 0) + 1\n",
    "    #uncomment these next three lines out if you want the relative frequencies\n",
    "#     factor=1.0/sum(freq.values())\n",
    "#     for sub in freq:\n",
    "#         freq[sub] = freq[sub]*factor\n",
    "    return freq\n",
    "\n",
    "#return a list of sequences for a given species and subfamily\n",
    "#ex: get_subfamily(\"humans\", \"AluJo\")\n",
    "def get_subfamily(species, subfamily):\n",
    "    records = SeqIO.parse(\"data/\" + species + \".fasta\", \"fasta\")\n",
    "    return [record for record in records if subfamily in record.id]\n",
    "\n",
    "##return a list of sequences for a given species and subfamily on a chromosome\n",
    "#ex: get_subfamily_chr(\"humans\", \"AluJo\", 1)\n",
    "def get_subfamily_chr(species, subfamily, chromosome):\n",
    "    records = get_subfamily(species, subfamily)\n",
    "    return [record for record in records if \"chr\"+str(chromosome) in record.description]\n",
    "\n",
    "#retrieve a sequence for a given speicies based on its description\n",
    "def get_sequence(species, description):\n",
    "    records = SeqIO.parse(\"data/\" + species + \".fasta\", \"fasta\")\n",
    "    return [record for record in records if description == record.description]\n",
    "\n",
    "#parses location information from description string\n",
    "def get_location(description):\n",
    "    location = description.split(' ')[1].split(':')\n",
    "    start, end = location[1].split('-')\n",
    "    return [location[0].split(\"=\")[1], int(start), int(end)]\n",
    "\n",
    "# #reverse lookup for sequence description given species, single chromosome, start, and end \n",
    "# def description_lookup(species, subfamily, chromosome, start, end): \n",
    "#     sequences = pickle.load(file=open(\"data/\"+ species + \"/\" + species +\"_\" + subfamily + \".p\", \"rb\"))\n",
    "#     description = chromosome+\":\"+str(start) + \"-\" + str(end) \n",
    "#     for s in sequences: \n",
    "#         desc = s.description.split(\" \")[1][6:]\n",
    "#         if desc == description: \n",
    "#             return s.seq \n",
    "\n",
    "#reverse lookup for sequence given lists of chromosomes, start, and end\n",
    "def description_lookup(species, subfamily, chromosomes, starts, ends): \n",
    "    assert len(chromosomes) == len(starts) and len(starts) == len(ends) and len(chromosomes) == len(ends)\n",
    "    lookup = {} \n",
    "    result = []\n",
    "    sequences = pickle.load(file=open(\"data/\"+ species + \"/\" + species +\"_\" + subfamily + \".p\", \"rb\"))\n",
    "    for s in sequences: \n",
    "        desc = s.description.split(\" \")[1][6:]\n",
    "        lookup[desc] = s.seq\n",
    "    descriptions = [str(chromosomes[i]) + \":\" + str(starts[i]) + \"-\" + str(ends[i]) for i in range(len(chromosomes))] \n",
    "    for d in descriptions: \n",
    "        result.append(lookup[d])\n",
    "    return result         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alu': 4658,\n",
       " 'AluJb': 131759,\n",
       " 'AluJo': 81375,\n",
       " 'AluJr': 88503,\n",
       " 'AluJr4': 20966,\n",
       " 'AluSc': 36338,\n",
       " 'AluSc5': 7018,\n",
       " 'AluSc8': 23028,\n",
       " 'AluSg': 38681,\n",
       " 'AluSg4': 7603,\n",
       " 'AluSg7': 9159,\n",
       " 'AluSp': 53809,\n",
       " 'AluSq': 19866,\n",
       " 'AluSq10': 2165,\n",
       " 'AluSq2': 63875,\n",
       " 'AluSq4': 1906,\n",
       " 'AluSx': 123022,\n",
       " 'AluSx1': 123492,\n",
       " 'AluSx3': 34198,\n",
       " 'AluSx4': 11540,\n",
       " 'AluSz': 107707,\n",
       " 'AluSz6': 49944,\n",
       " 'AluY': 110881,\n",
       " 'AluYa8': 368,\n",
       " 'AluYd8': 241,\n",
       " 'AluYe5': 1378,\n",
       " 'AluYf1': 2025,\n",
       " 'AluYg6': 899,\n",
       " 'AluYh9': 165,\n",
       " 'AluYi6': 470,\n",
       " 'AluYk11': 1341,\n",
       " 'AluYk12': 219}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequencies(\"humans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Threaded Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pairings(species1, species2, subfamily):\n",
    "    species1_records = get_subfamily(species1, subfamily)\n",
    "    species2_records = get_subfamily(species2, subfamily)\n",
    "    filename = species1 + \"_\" + species1 + \"_\" + subfamily + \".csv\"\n",
    "    file=open(filename,\"w+\")\n",
    "    wr = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "    f = IntProgress(min=0, max=len(species1_records))\n",
    "    display(f)\n",
    "    for sequence1 in species1_records:\n",
    "        matches = [distance(str(sequence1.seq), str(sequence2.seq)) for sequence2 in species2_records]\n",
    "        match = species2_records[np.argmin(matches)]\n",
    "        location1 = get_location(sequence1.description)\n",
    "        location2 = get_location(match.description)\n",
    "        data = np.concatenate([location1, location2, [abs(location1[1] - location2[1])], [str(sequence1.seq)], [str(match.seq)]]) \n",
    "        wr.writerow(data)\n",
    "        f.value += 1\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_pairings(\"humans\", \"chimps\", \"AluJo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreaded Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters here\n",
    "species1 = \"humans\"\n",
    "species2 = \"chimps\"\n",
    "subfamily = \"AluJo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then run this cell\n",
    "print(\"loading \" + species1 + \" data...\")\n",
    "species1_records = get_subfamily(species1, subfamily)\n",
    "print(\"loading \" + species2 + \" data...\")\n",
    "species2_records = get_subfamily(species2, subfamily)\n",
    "generate_pairings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_match(sequence):\n",
    "    matches = [distance(str(sequence.seq), str(sequence2.seq)) for sequence2 in species2_records]\n",
    "    match = species2_records[np.argmin(matches)]\n",
    "    location1 = get_location(sequence.description)\n",
    "    location2 = get_location(match.description)\n",
    "    data = np.concatenate([location1, location2, [abs(location1[1] - location2[1])], [str(sequence.seq)], [str(match.seq)]]) \n",
    "    return data\n",
    "    \n",
    "def generate_pairings():\n",
    "    filename = species1 + \"_\" + species2 + \"_\" + subfamily + \".csv\"\n",
    "    print(\"starting matching\")\n",
    "    p = mp.Pool(mp.cpu_count() + 2)\n",
    "    with open(filename, 'w+') as f:\n",
    "        wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "        with tqdm(total=len(species1_records), unit=\"match\") as pbar:\n",
    "            for i, result in tqdm(enumerate(p.imap(func=find_match, iterable=species1_records))):\n",
    "                # (filename, count) tuples from worker\n",
    "                pbar.update()\n",
    "                wr.writerow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = SeqIO.parse(\"data/\" + \"humans\" + \".fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = SeqIO.parse(\"data/\" + \"chimps\" + \".fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(str(next(h).seq),str(next(c).seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = iter([1, 2, 3, 4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = [f for f in listdir(\"data\") if \"_\" not in f]\n",
    "genomes.remove(\"Humans\")\n",
    "tasks = [pickle.load(file=open(\"tasks/\" + f, \"rb\")) for f in listdir(\"tasks\")]\n",
    "tasks = [t for t in tasks if t.species1==\"Humans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[5758, 5725, 5732, 5662, 5710, 5768, 5767, 5750, 5692, 5734, 5904, 5666, 5699]\n"
     ]
    }
   ],
   "source": [
    "for a in alu[:1]:\n",
    "    strings = []\n",
    "    row=np.inf\n",
    "    for g in genomes:\n",
    "        t = [t for t in tasks if t.species2==g and t.subfamily==a][0]\n",
    "        row_count = sum(1 for row in csv.reader(open(\"results/\"+t.filename()+\".csv\", \"r\")))\n",
    "        row = min(row, row_count)\n",
    "    row=20\n",
    "    t = [t for t in tasks if t.subfamily==a][0]\n",
    "    df = pd.read_csv(\"results/\"+t.filename()+\".csv\", header=None)\n",
    "    strings.append(df[df.columns[8]][:row].str.cat())\n",
    "    for g in genomes:\n",
    "        t = [t for t in tasks if t.species2==g and t.subfamily==a][0]\n",
    "        df = pd.read_csv(\"results/\"+t.filename()+\".csv\", header=None)\n",
    "        strings.append(df[df.columns[9]][:row].str.cat())\n",
    "    print(len(strings))\n",
    "    ls = [len(s) for s in strings]\n",
    "    print(ls)\n",
    "    minl = min([len(s) for s in strings])\n",
    "    with open(\"clustal/\"+a+\"smallish.fasta\", \"w+\", newline=\"\") as file:\n",
    "        wr = csv.writer(file)\n",
    "        wr.writerow([\">Humans_\"+a])\n",
    "        wr.writerow([strings[0]])\n",
    "        for i in range(1, len(strings)):\n",
    "            wr.writerow([\">\"+genomes[i-1]+\"_\"+a])\n",
    "            wr.writerow([strings[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.1 s ± 93.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_task(tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(description):\n",
    "    location = description.split(' ')[1].split(':')\n",
    "    start, end = location[1].split('-')\n",
    "    return [location[0].split(\"=\")[1], int(start), int(end)]\n",
    "\n",
    "def run_task(task):\n",
    "    batch_size = min(20, task.remaining())\n",
    "    # print(data)\n",
    "    species1_records = pickle.load(open(\"data/\" + task.species1 + \"/\" + task.species1 + \"_\" + task.subfamily + \".p\", \"rb\"))[task.completed:task.completed+batch_size]\n",
    "    species2_records = pickle.load(open(\"data/\" + task.species2 + \"/\" + task.species2 + \"_\" + task.subfamily + \".p\", \"rb\"))\n",
    "    datas = []\n",
    "    for sequence1 in species1_records:\n",
    "        # matches = [editdistance.eval(str(sequence1.seq), str(sequence2.seq)) for sequence2 in species2_records]\n",
    "        matches = [edlib.align(str(sequence1.seq), str(sequence2.seq), task = \"editDistance\")[\"editDistance\"] for sequence2 in species2_records]\n",
    "        min_index = np.argmin(matches)\n",
    "        match = species2_records[min_index]\n",
    "        location1 = get_location(sequence1.description)\n",
    "        location2 = get_location(match.description)\n",
    "        data = np.concatenate([location1, location2, [matches[min_index]], [abs(location1[1] - location2[1])], [str(sequence1.seq)], [str(match.seq)]])\n",
    "        datas.append(data)\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e6a42d890f17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-0a35f5e59afe>\u001b[0m in \u001b[0;36mrun_task\u001b[1;34m(task)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msequence1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspecies1_records\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# matches = [editdistance.eval(str(sequence1.seq), str(sequence2.seq)) for sequence2 in species2_records]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0medlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"editDistance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"editDistance\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msequence2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspecies2_records\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mmin_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecies2_records\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-0a35f5e59afe>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msequence1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspecies1_records\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# matches = [editdistance.eval(str(sequence1.seq), str(sequence2.seq)) for sequence2 in species2_records]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0medlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"editDistance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"editDistance\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msequence2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspecies2_records\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mmin_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecies2_records\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results/\"+tasks[0].filename()+\".csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCCAGGCACAGTGGCTCATGCCTATAATCCCAGCTCTTTGGGAGGTCAAGGCGGGCAGATTGCTTGAGCCCAGGAGTTCAAGACTAGCCTGGGCAACATAGTGAGATCTGTCACTACTAAAAATAAAAAAGTTAGTTGGGCGTAGTGGCATGCACCTAGTATTCCCAGCTACTAAGGAGGCTAAGGCAGGAGGATTACTTGAGTCCGGGAGGTTGAGGTTGCAGTGAGCTGATCATGCCATACTACTCCAGCCTGGGCTACAGAGCGAGACCCTGTCTTGAAGAAAAAAAAAAAGGCCAGACACAATGGCTCACACCTGTAATCTCAGCACTTTGGGAGACTGAAGTGGGCAGATCACTTGAGCCCAGGAGTTTGAGACCAGCCTGGGTAATATAGTGAGACCACCGTCTCTACAAAAATACAAAAATTAGCTGGGCATGGTGGTGCACCTGTGGTCCCAGCTACTCGAGAGGCTGAAGTGGGAGGATCACCTGAGCCCAGGAGGTTAAGGCTGCAGTGAGCCGAGATCACGCACCGTACTCCAGCCTGGGTGACAGAGTGAGACCATGTCTCAAAAAAAAAAAAGGCTAGGCACAGTGGCTCACACCTGTAAGCCCAACACTTTGGGAGGCTGAGGTAGGAAGATTGAGTTCAGGAATTCAAGACTAACCTGGGCAACATAGTGAGACCTCATCTCTACTAAAAATTTAAGAAATTAGCTGGGCGTGGTGGCATGTGCCTATAGTCCCAGCTGCAGTCCCAGCTACTCAGGAGGCTGAGGTGAAAGGACGGCTTGAGCCTGGGAGGTTAAGGCTGCAGTAGTCTTGATCACACCACTGCACTACAAGTCCGGGTGACAGAGTGAAACCCTGCCTCCAATAAAAAAAAAAAGAAAGAAAGAAAAAATTAGCCGGGCATGGTGGCACCTGCCTGTGATCCCAGCTACTTGGGAGTTTACTTGGGCCTGGGAGGTAGAAGCTGCACTGAGCCGTGATGGTGCCATTGCACCCCAGCCTGAGTGACAGAGTGAGACCCTGTCTCAAAAAATAAAAATAAAGGCCAGGCACAGTGGCTCATGCCTGTAATCCCAATACTTTAGGAGTCTGGGGCAGGACAATTGCTTGAGCCAGAATTTGAGACCAGCCTGGGCAACATGGTGAAATCTCATCTCTACAAAAAGCAAGTCAAAATTAGCTGGGTGATGTGGTGCACATCTGTATTAATCCCAGCTACTTGGGAGGCCAAGGCAGGAGGATCACTTGAACCAGTAGGTGGAGGCTGCAGTAAACCAAGATTGCACCACTGCACTCCAACCTGGGCTGCAGAGTGAGGCCTTGTCTCAAAAAAAAAAAAAGAGAAAGAAAAAAAATTAGCCAGGCATTGTGGTGTGCACCTGTAGTCCCAGCTACTCGGGAGGCTGAGGTGGGAAGATGGCTTGGCCCGGAGGGGGTCAAGGCTGCAGTGAGTTGTAATGGTGCCACTGCACTCCAGCCTGGGCAACAGAGCAAGACCCTGTCTCAAAACAAAACAAAATAAAACAAACAGAAAAAAGAAGAGGAAAAGGAGCCGATGTGACTCACACCTGCAATCCCAGGGCTTTGGGAGGCCAAGGTGGGAGGATTGCTTGAACCCGGGAGGTTGAGGCTGCAATGAGCTGAGATTGCACCACTGTACCCCAGCCTAGGCGACAGAGCAAGACTGCCACCGAGAAAAAGACCACCCTGGGCAATAGGATGGGACCCCATCTCTACAAAAAAAATTTGTTTTAATTAGCCAGGCATGGTGGCAGGCACCTCTATTCCCAGCTACTTGGGAGGCCAAGGCAGGAGGATCACTTGAGCCAAGGAGGTTGAGGCTGCAGCAAGCCATGATTGCATCACTGCACTCCAACCCCACCACAGAGCGAGACCCTGTCTCTAAAAACCTAACTGGATATAGTGGCACACGCCTGTGGTCCCAGCTACTCGGGAGGCTCAGGCGGGAGCATCGTTTGAGCCCAGGAGGTCGAGGTTGCAGTCAGCTGAGATCGCACCACTGCACTCTAGCCTGGGTGACAGAGCAAGACCCTGTCTCAGAAAAAAAGAAAAAAAGGCCAGGTGCGGTGGCTCACGCCTGTAATCCCAACACTTTGGGAGGCCAAGGCGGGTAGATTGCTTGAGCCTAGGAGTTATAGGCCACCCTGGGCAACATGATGAAGCCCTGTTTCTACAGAAAATACAAAAATTAGCCAGGCATGGTGGTGCACCCCTGTAGTCCCAGCTACTCAGGGGCGGAGGTAGGAGGATCGCTTGAGCCCAGGAAGTGAAAGCTAGAGTGAGCTATGATTGCACCACTGCACTCCAGCCTGGGCGACAGGGTGAGACCCTGTCTCAAAAGAAAACAAGAAAGAAAAAAGAAAAA'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[8]][np.random.permutation(len(df)-50)][:10].str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2, 217, 557, 516,  24, 162,  26, 174, 477, 404, 178, 273, 554,\n",
       "         1,  42,  43, 372, 242, 134,  27, 575, 193,  58, 194, 327, 186,\n",
       "       547,  25,  81, 496, 172, 587, 306, 449, 116, 227, 337, 167, 565,\n",
       "       100, 150, 214,  83, 454,   7, 431, 148, 245, 544, 102,  38, 323,\n",
       "       358, 405,  33, 467, 313,  97,  49, 301, 156, 187, 275, 324, 266,\n",
       "       308, 435, 179, 383, 182, 231, 529,  50,  55, 410, 486, 257,  87,\n",
       "       535, 283,   9, 513, 122,  93, 142, 244, 334, 265,  32,  19, 480,\n",
       "       338,  72,  48, 318, 200, 281, 497, 274, 183, 586, 287, 310, 413,\n",
       "       491,  90, 104, 169, 425, 246, 508,  59, 195,  73, 341, 584, 149,\n",
       "       199,  35, 230, 270, 391,  65, 123, 492, 125, 514, 533, 127, 384,\n",
       "       299, 555,  86, 571,   8, 415, 568, 368, 233, 263, 559, 466, 262,\n",
       "       362,  54, 447, 158, 403, 519, 421, 379, 234, 294,  21, 475, 208,\n",
       "       550, 417,   4, 225, 295, 105, 332, 414, 463, 309, 128, 385,  95,\n",
       "        88,  37, 111, 576, 345, 373, 328, 307,   5, 185, 259, 304, 212,\n",
       "       271, 558, 374, 420, 139, 133, 567, 498, 517, 541, 460, 524, 282,\n",
       "        29, 268,  28,  71, 355, 254, 365, 552, 462, 236, 317,  14, 357,\n",
       "       510, 561, 536, 279, 315, 144, 298, 288,  79,  57, 378, 470, 114,\n",
       "       538, 291, 347, 220, 173, 577, 494,  51, 256,  12, 428, 219, 351,\n",
       "       258, 177, 490, 456, 371, 464, 458, 321, 348,  60, 147,  78, 566,\n",
       "       518, 202, 500, 422,  70, 163, 474, 237, 352, 255, 406, 192, 579,\n",
       "       124, 207,  11, 367, 448, 504,  85, 228, 106, 563,  15,  64, 289,\n",
       "       284, 203, 229, 107, 366, 292, 326, 113,  34, 171, 574,  23, 527,\n",
       "       108, 277, 507, 540, 416, 118, 296, 240, 409, 534, 249, 226, 402,\n",
       "       451, 503, 382, 401,  82, 333, 260, 390, 375, 523, 336, 441, 166,\n",
       "       484, 553, 589,  20, 482, 210, 221,  84, 223, 278, 419, 243, 502,\n",
       "       461, 542,  41, 439, 369, 215, 376,  74, 361,  68, 232, 136, 253,\n",
       "       483, 360, 204, 267,  22, 572, 512,  10, 570, 426, 350,  67, 115,\n",
       "        92, 427, 164,  17, 443,  52,  47, 465, 580, 481, 485, 325, 238,\n",
       "       290, 311,   6, 157, 206, 520, 316, 305, 511, 424, 101, 180, 138,\n",
       "        18, 353,  62, 191,  80, 285, 430, 506, 331, 583, 218,  66, 176,\n",
       "       190, 330, 551, 528,  61, 479,   3, 400, 569, 446, 392, 340, 560,\n",
       "       349, 588, 398, 239, 151, 269, 235, 364, 476, 585, 175, 354, 145,\n",
       "       137,  75, 335, 339, 487, 442, 440,  69, 531, 537, 300, 272, 346,\n",
       "        96, 397, 444, 209, 573, 473, 135,  89, 556, 211, 407, 543, 224,\n",
       "       131,  45, 521, 581, 469, 564, 154, 399, 188, 432, 132, 276, 445,\n",
       "       213, 468, 505, 418, 493, 168, 343, 389, 302, 438, 437, 423, 530,\n",
       "       197,  46, 546, 457, 248, 196,  40, 160, 184, 471, 386,  63, 117,\n",
       "       312,  76,  91, 478, 429,  98, 455, 562, 152, 408, 110, 165, 303,\n",
       "       161,  30, 250,   0, 526, 363, 181, 411, 329, 501, 170,  39, 140,\n",
       "       129, 342, 189, 434, 216,  36, 109, 472, 539,  13, 120, 198, 320,\n",
       "       155, 548, 146, 433, 241, 436, 286, 130, 119, 459, 499, 578, 319,\n",
       "        77, 388, 293, 396, 412, 452, 488, 251, 515,  53, 495, 344, 359,\n",
       "       380, 126,  94, 143, 450, 112,  31, 370, 153, 264, 159, 297, 387,\n",
       "       222, 545, 395, 356, 525, 509, 280, 247, 205, 532, 201, 522, 381,\n",
       "       314, 394, 453, 377, 252, 121,  99, 103, 393, 261,  56, 322, 582,\n",
       "        16,  44, 549, 489, 141])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = []\n",
    "[b.append(c) for c in a if c==1]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
