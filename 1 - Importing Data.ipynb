{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio import SeqFeature\n",
    "from Bio.Alphabet import IUPAC\n",
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "import numpy as np\n",
    "import csv\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import product, combinations\n",
    "from os import listdir, mkdir\n",
    "import pickle\n",
    "#ocf cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Greens', 'Gorillas', 'Goldens', 'Chimps', 'Bushbaby', 'Bonobos', 'Baboons']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genomes = [f for f in listdir(\"data\") if \"_\" not in f]\n",
    "genomes[:7][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    }
   ],
   "source": [
    "genomes = [f for f in listdir(\"data\") if \"_\" not in f]\n",
    "genomes.remove(\"Humans\")\n",
    "alu = [\"AluJb\", \"AluJo\", \"AluJr\", \"AluJr4\", \"AluSc\", \"AluSc5\", \"AluSc8\", \"AluSg\", \"AluSg4\", \"AluSg7\", \"AluSp\", \"AluSq\", \"AluSq10\", \"AluSq2\", \"AluSq4\", \"AluSx\", \"AluSx1\", \"AluSx3\", \"AluSx4\", \"AluSz\", \"AluSz6\", \"AluY\"]\n",
    "# pairings = list(combinations(genomes, 2))\n",
    "# print(len(pairings))\n",
    "tasks = list(product(product([\"Humans\"], genomes[:7][::-1]), alu))\n",
    "print(len(tasks))\n",
    "create_tasks(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = Task(tasks[1])\n",
    "t2 = Task(tasks[1])\n",
    "t2.update(5)\n",
    "t1 == t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "tasks = [pickle.load(file=open(\"tasks/\" + f, \"rb\")) for f in listdir(\"tasks\")]\n",
    "started = [task for task in tasks if task.species1 == \"Humans\"]\n",
    "# finished = [task for task in tasks if task.finished()]\n",
    "print(len(started))\n",
    "df = pd.read_csv(\"results/\"+started[0].filename()+\".csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = [f for f in listdir(\"data\") if \"_\" not in f]\n",
    "genomes.remove(\"Humans\")\n",
    "for a in alu[:1]:\n",
    "    for genome in genomes[:1]:\n",
    "        string = []\n",
    "        for task in started:\n",
    "            if task.species2 == genome and task.subfamily == alu:\n",
    "                df = pd.read_csv(\"results/\"+task.filename()+\".csv\", header=None)\n",
    "                print(df['8'].str.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>192937858</td>\n",
       "      <td>192938175</td>\n",
       "      <td>chr1</td>\n",
       "      <td>171366085</td>\n",
       "      <td>171366402</td>\n",
       "      <td>24</td>\n",
       "      <td>21571773</td>\n",
       "      <td>GCCGGGCATGGTGGCTCACTCTTGTTAATCCCAGCACTTTGGGAAG...</td>\n",
       "      <td>GCCGGGCATGGTGGCTCATTCTTGTTAATCCCAGCACTTTGGGAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>24117116</td>\n",
       "      <td>24117383</td>\n",
       "      <td>chr1</td>\n",
       "      <td>26355737</td>\n",
       "      <td>26356001</td>\n",
       "      <td>25</td>\n",
       "      <td>2238621</td>\n",
       "      <td>CCCAGCACTTTGGGAGGCCAAGGTGGAGGATCACTTGGGTCCAGGA...</td>\n",
       "      <td>CCCAGCACTTTGGGAGGCCAAGGCGGAGGATCACTTGAGCCCAGGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>32505606</td>\n",
       "      <td>32505884</td>\n",
       "      <td>chr1</td>\n",
       "      <td>34701911</td>\n",
       "      <td>34702187</td>\n",
       "      <td>25</td>\n",
       "      <td>2196305</td>\n",
       "      <td>GGCCAGGTGGTGGCTTATATCTGTAATCCCACCACTTTGGGAGGCT...</td>\n",
       "      <td>GGCCAGGTGGTGGCTTATATCTATAATCCCATCACTTTGGGAGGCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>54525648</td>\n",
       "      <td>54525956</td>\n",
       "      <td>chr9</td>\n",
       "      <td>95122753</td>\n",
       "      <td>95123061</td>\n",
       "      <td>48</td>\n",
       "      <td>40597105</td>\n",
       "      <td>GGCCAGGCACAGCGGCTCACACCTGTAATCCCAGCACTTTGGGAGG...</td>\n",
       "      <td>GGCCAGGTGCAGGGGCTCACGCCTATAATCCTAGTACTTTGGGAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>236977955</td>\n",
       "      <td>236978230</td>\n",
       "      <td>chr1</td>\n",
       "      <td>212128917</td>\n",
       "      <td>212129192</td>\n",
       "      <td>26</td>\n",
       "      <td>24849038</td>\n",
       "      <td>GGCTGGGCGTGGTGGCTCATGCCTATAATCCCAGCACTTTGGGAAG...</td>\n",
       "      <td>GGCTGGGTGTGGTGGCTCATGCCTATAATCCCAGCACTTTGGGAAG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0          1          2     3          4          5   6         7  \\\n",
       "0  chr1  192937858  192938175  chr1  171366085  171366402  24  21571773   \n",
       "1  chr1   24117116   24117383  chr1   26355737   26356001  25   2238621   \n",
       "2  chr1   32505606   32505884  chr1   34701911   34702187  25   2196305   \n",
       "3  chr1   54525648   54525956  chr9   95122753   95123061  48  40597105   \n",
       "4  chr1  236977955  236978230  chr1  212128917  212129192  26  24849038   \n",
       "\n",
       "                                                   8  \\\n",
       "0  GCCGGGCATGGTGGCTCACTCTTGTTAATCCCAGCACTTTGGGAAG...   \n",
       "1  CCCAGCACTTTGGGAGGCCAAGGTGGAGGATCACTTGGGTCCAGGA...   \n",
       "2  GGCCAGGTGGTGGCTTATATCTGTAATCCCACCACTTTGGGAGGCT...   \n",
       "3  GGCCAGGCACAGCGGCTCACACCTGTAATCCCAGCACTTTGGGAGG...   \n",
       "4  GGCTGGGCGTGGTGGCTCATGCCTATAATCCCAGCACTTTGGGAAG...   \n",
       "\n",
       "                                                   9  \n",
       "0  GCCGGGCATGGTGGCTCATTCTTGTTAATCCCAGCACTTTGGGAAG...  \n",
       "1  CCCAGCACTTTGGGAGGCCAAGGCGGAGGATCACTTGAGCCCAGGA...  \n",
       "2  GGCCAGGTGGTGGCTTATATCTATAATCCCATCACTTTGGGAGGCT...  \n",
       "3  GGCCAGGTGCAGGGGCTCACGCCTATAATCCTAGTACTTTGGGAGG...  \n",
       "4  GGCTGGGTGTGGTGGCTCATGCCTATAATCCCAGCACTTTGGGAAG...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = [f.split(\".\")[0] for f in listdir(\"data\") if \".fasta\" in f]\n",
    "alu = [\"AluJb\", \"AluJo\", \"AluJr\", \"AluJr4\", \"AluSc\", \"AluSc5\", \"AluSc8\", \"AluSg\", \"AluSg4\", \"AluSg7\", \"AluSp\", \"AluSq\", \"AluSq10\", \"AluSq2\", \"AluSq4\", \"AluSx\", \"AluSx1\", \"AluSx3\", \"AluSx4\", \"AluSz\", \"AluSz6\", \"AluY\"]\n",
    "create_pickles(genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Task(tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(obj=t, file=open(t.filename(), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = pickle.load(file=open(t.filename(), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the frequencies for each subfamily in a genome\n",
    "#ex: get_frequencies(\"humans\")\n",
    "class Task():\n",
    "    def __init__(self,task):\n",
    "        self.species1 = task[0][0]\n",
    "        self.species2 = task[0][1]\n",
    "        self.subfamily = task[1]\n",
    "        self.total = len(pickle.load(file=open(\"data/\"+self.species1 + \"/\" + self.species1+\"_\"+self.subfamily + \".p\", \"rb\")))\n",
    "        self.completed = 0\n",
    "    def filename(self):\n",
    "        return self.species1 + \"_\" + self.species2 + \"_\" + self.subfamily + \".p\"\n",
    "    def update(self,amount):\n",
    "        self.completed += amount\n",
    "    def finished(self):\n",
    "        return self.completed == self.total\n",
    "    def remaining(self):\n",
    "        return self.total - self.completed\n",
    "    def __eq__(self, obj):\n",
    "        return (self.species1 == obj.species1) & (self.species2 == obj.species2) & (self.subfamily == obj.subfamily)\n",
    "def create_tasks(tasks):\n",
    "#warning: only run once, will reset progress for tasks\n",
    "    for task in tasks:\n",
    "        t = Task(task)\n",
    "        pickle.dump(t, open(\"tasks/\"+t.filename(), \"wb\"))\n",
    "#     task_list = [Task(task) for task in tasks]\n",
    "#     pickle.dump(obj=task_list, file=open(\"progress.p\", \"wb\"))\n",
    "def create_pickles(genomes):\n",
    "    d = {}\n",
    "    for g in genomes:\n",
    "        records = SeqIO.parse(\"data/\" + g + \".fasta\", \"fasta\")\n",
    "        for a in alu:\n",
    "            d[a]=[]\n",
    "        for r in records:\n",
    "            subfamily = r.id.split(\"_\")[2]\n",
    "            if subfamily in d.keys():\n",
    "                d[subfamily].append(r)\n",
    "        mkdir(\"data/\" + g)\n",
    "        for sub, seqs in d.items():\n",
    "            path = \"data/\" + g + \"/\" + g + \"_\" + sub + \".p\"\n",
    "            pickle.dump(seqs, open(path, \"wb\"))\n",
    "        \n",
    "        \n",
    "def get_frequencies(species):\n",
    "    records = SeqIO.parse(\"data/\" + species + \".fasta\", \"fasta\")\n",
    "    freq = {}\n",
    "    for r in records:\n",
    "        subfamily = r.id.split(\"_\")[2]\n",
    "        freq[subfamily] = freq.get(subfamily, 0) + 1\n",
    "    #uncomment these next three lines out if you want the relative frequencies\n",
    "#     factor=1.0/sum(freq.values())\n",
    "#     for sub in freq:\n",
    "#         freq[sub] = freq[sub]*factor\n",
    "    return freq\n",
    "\n",
    "#return a list of sequences for a given species and subfamily\n",
    "#ex: get_subfamily(\"humans\", \"AluJo\")\n",
    "def get_subfamily(species, subfamily):\n",
    "    records = SeqIO.parse(\"data/\" + species + \".fasta\", \"fasta\")\n",
    "    return [record for record in records if subfamily in record.id]\n",
    "\n",
    "##return a list of sequences for a given species and subfamily on a chromosome\n",
    "#ex: get_subfamily_chr(\"humans\", \"AluJo\", 1)\n",
    "def get_subfamily_chr(species, subfamily, chromosome):\n",
    "    records = get_subfamily(species, subfamily)\n",
    "    return [record for record in records if \"chr\"+str(chromosome) in record.description]\n",
    "\n",
    "#retrieve a sequence for a given speicies based on its description\n",
    "def get_sequence(species, description):\n",
    "    records = SeqIO.parse(\"data/\" + species + \".fasta\", \"fasta\")\n",
    "    return [record for record in records if description == record.description]\n",
    "\n",
    "#parses location information from description string\n",
    "def get_location(description):\n",
    "    location = description.split(' ')[1].split(':')\n",
    "    start, end = location[1].split('-')\n",
    "    return [location[0].split(\"=\")[1], int(start), int(end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alu': 4658,\n",
       " 'AluJb': 131759,\n",
       " 'AluJo': 81375,\n",
       " 'AluJr': 88503,\n",
       " 'AluJr4': 20966,\n",
       " 'AluSc': 36338,\n",
       " 'AluSc5': 7018,\n",
       " 'AluSc8': 23028,\n",
       " 'AluSg': 38681,\n",
       " 'AluSg4': 7603,\n",
       " 'AluSg7': 9159,\n",
       " 'AluSp': 53809,\n",
       " 'AluSq': 19866,\n",
       " 'AluSq10': 2165,\n",
       " 'AluSq2': 63875,\n",
       " 'AluSq4': 1906,\n",
       " 'AluSx': 123022,\n",
       " 'AluSx1': 123492,\n",
       " 'AluSx3': 34198,\n",
       " 'AluSx4': 11540,\n",
       " 'AluSz': 107707,\n",
       " 'AluSz6': 49944,\n",
       " 'AluY': 110881,\n",
       " 'AluYa8': 368,\n",
       " 'AluYd8': 241,\n",
       " 'AluYe5': 1378,\n",
       " 'AluYf1': 2025,\n",
       " 'AluYg6': 899,\n",
       " 'AluYh9': 165,\n",
       " 'AluYi6': 470,\n",
       " 'AluYk11': 1341,\n",
       " 'AluYk12': 219}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequencies(\"humans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Threaded Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_pairings(species1, species2, subfamily):\n",
    "    species1_records = get_subfamily(species1, subfamily)\n",
    "    species2_records = get_subfamily(species2, subfamily)\n",
    "    filename = species1 + \"_\" + species1 + \"_\" + subfamily + \".csv\"\n",
    "    file=open(filename,\"w+\")\n",
    "    wr = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "    f = IntProgress(min=0, max=len(species1_records))\n",
    "    display(f)\n",
    "    for sequence1 in species1_records:\n",
    "        matches = [distance(str(sequence1.seq), str(sequence2.seq)) for sequence2 in species2_records]\n",
    "        match = species2_records[np.argmin(matches)]\n",
    "        location1 = get_location(sequence1.description)\n",
    "        location2 = get_location(match.description)\n",
    "        data = np.concatenate([location1, location2, [abs(location1[1] - location2[1])], [str(sequence1.seq)], [str(match.seq)]]) \n",
    "        wr.writerow(data)\n",
    "        f.value += 1\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_pairings(\"humans\", \"chimps\", \"AluJo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreaded Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters here\n",
    "species1 = \"humans\"\n",
    "species2 = \"chimps\"\n",
    "subfamily = \"AluJo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then run this cell\n",
    "print(\"loading \" + species1 + \" data...\")\n",
    "species1_records = get_subfamily(species1, subfamily)\n",
    "print(\"loading \" + species2 + \" data...\")\n",
    "species2_records = get_subfamily(species2, subfamily)\n",
    "generate_pairings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_match(sequence):\n",
    "    matches = [distance(str(sequence.seq), str(sequence2.seq)) for sequence2 in species2_records]\n",
    "    match = species2_records[np.argmin(matches)]\n",
    "    location1 = get_location(sequence.description)\n",
    "    location2 = get_location(match.description)\n",
    "    data = np.concatenate([location1, location2, [abs(location1[1] - location2[1])], [str(sequence.seq)], [str(match.seq)]]) \n",
    "    return data\n",
    "    \n",
    "def generate_pairings():\n",
    "    filename = species1 + \"_\" + species2 + \"_\" + subfamily + \".csv\"\n",
    "    print(\"starting matching\")\n",
    "    p = mp.Pool(mp.cpu_count() + 2)\n",
    "    with open(filename, 'w+') as f:\n",
    "        wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "        with tqdm(total=len(species1_records), unit=\"match\") as pbar:\n",
    "            for i, result in tqdm(enumerate(p.imap(func=find_match, iterable=species1_records))):\n",
    "                # (filename, count) tuples from worker\n",
    "                pbar.update()\n",
    "                wr.writerow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = SeqIO.parse(\"data/\" + \"humans\" + \".fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = SeqIO.parse(\"data/\" + \"chimps\" + \".fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(str(next(h).seq),str(next(c).seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = iter([1, 2, 3, 4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = [f for f in listdir(\"data\") if \"_\" not in f]\n",
    "genomes.remove(\"Humans\")\n",
    "tasks = [pickle.load(file=open(\"tasks/\" + f, \"rb\")) for f in listdir(\"tasks\")]\n",
    "tasks = [t for t in tasks if t.species1==\"Humans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[3590, 3559, 3590, 3520, 3581, 3593, 3594, 3581, 3582, 3622, 3695, 3584, 3565]\n"
     ]
    }
   ],
   "source": [
    "for a in alu[:1]:\n",
    "    strings = []\n",
    "    row=np.inf\n",
    "    for g in genomes:\n",
    "        t = [t for t in tasks if t.species2==g and t.subfamily==a][0]\n",
    "        row_count = sum(1 for row in csv.reader(open(\"results/\"+t.filename()+\".csv\", \"r\")))\n",
    "        row = min(row, row_count)\n",
    "    row=13\n",
    "    t = [t for t in tasks if t.subfamily==a][0]\n",
    "    df = pd.read_csv(\"results/\"+t.filename()+\".csv\", header=None)\n",
    "    strings.append(df[df.columns[8]][:row].str.cat())\n",
    "    for g in genomes:\n",
    "        t = [t for t in tasks if t.species2==g and t.subfamily==a][0]\n",
    "        df = pd.read_csv(\"results/\"+t.filename()+\".csv\", header=None)\n",
    "        strings.append(df[df.columns[9]][:row].str.cat())\n",
    "    print(len(strings))\n",
    "    ls = [len(s) for s in strings]\n",
    "    print(ls)\n",
    "    minl = min([len(s) for s in strings])\n",
    "    with open(\"clustal/\"+a+\"small.fasta\", \"w+\", newline=\"\") as file:\n",
    "        wr = csv.writer(file)\n",
    "        wr.writerow([\">Humans_\"+a])\n",
    "        wr.writerow([strings[0]])\n",
    "        for i in range(1, len(strings)):\n",
    "            wr.writerow([\">\"+genomes[i-1]+\"_\"+a])\n",
    "            wr.writerow([strings[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
